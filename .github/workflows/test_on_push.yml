name: Test on Push

on:
  pull_request:
    branches: [main]
  workflow_dispatch:

defaults:
  run:
    shell: bash

# UV will use the system python by default
env:
  UV_SYSTEM_PYTHON: 1

# Cancel any existing runs of this workflow on the same branch/pr
# We always want to build/deploy/test a new commit over an older one
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}
  cancel-in-progress: true

jobs:
  # Sets an output var to indicate if all changes are in docs files
  # This output is used to skip running code checks on docs changes
  changes:
    name: Filter changed files
    runs-on: mdb-dev
    outputs:
      not-docs: ${{ steps.filter.outputs.not-docs }}
    steps:
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          predicate-quantifier: "every"
          filters: |
            not-docs:
              - '!docs/**'  
              - '!**/*.md'

  # Run all of our static code checks here
  code_checking:
    name: Run static code checks
    runs-on: mdb-dev
    needs: changes
    steps:
      - name: Checkout
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        uses: actions/checkout@v4
      - name: Set up Python
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        uses: actions/setup-python@v5.1.0
        with:
          # I can't work out how to use vars.CI_PYTHON_VERSION for forks here in a nice way, so we have to hardcode it for forks
          python-version: ${{ vars.CI_PYTHON_VERSION || '3.10' }}

      # Checks the codebase for print() statements and fails if any are found
      # We should be using loggers instead
      - name: Check for print statements
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        run: |
          python tests/scripts/check_print_statements.py

      # Gathers a list of changed files for pre-commit to use
      - name: Get changed files
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        id: changed-files
        uses: tj-actions/changed-files@v41

      # Run pre-commit on all changed files
      # See .pre-commit-config.yaml for the list of checks
      - name: Run pre-commit
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        uses: pre-commit/action@v3.0.0
        with:
          extra_args: --files ${{ steps.changed-files.outputs.all_changed_files }}

      # Runs a few different checks against our many requirements files
      # to make sure they're in order
      - name: Check requirements files
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        run: |
          # We don't need to install mindsdb itself here because these are just static code checks
          uv pip install -r requirements/requirements-dev.txt

          python tests/scripts/check_requirements.py

  # Creates a matrix of environments to test against using matrix_includes.json
  # Used for installation checks below
  matrix_prep:
    name: Prepare matrix
    runs-on: mdb-dev
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4
      - id: set-matrix
        uses: JoshuaTheMiller/conditional-build-matrix@v2.0.1
        with:
          filter: "[?runOnBranch==`${{ github.ref }}` || runOnBranch==`always`]"

  # Check that our pip package is able to be installed in all of our supported environments
  check_install:
    name: Check pip installation
    needs: [changes, matrix_prep, code_checking]
    strategy:
      matrix: ${{fromJson(needs.matrix_prep.outputs.matrix)}}
    runs-on: ${{ matrix.runs_on }}
    steps:
      - name: Checkout
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        uses: actions/checkout@v4
      - name: Set up Python
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        uses: actions/setup-python@v5.1.0
        with:
          python-version: ${{ matrix.python-version }}
      # We have to install UV because (for now) these run in GH's runners
      - name: Setup uv
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "**/requirements*.txt" 
      - name: Check requirements files are installable
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        run: |
          # Install dev requirements and build our pip package
          uv pip install -r requirements/requirements-dev.txt
          python setup.py sdist

          # Install from the pip package
          # If we install from source, we don't know if the pip package is installable.
          cd dist
          uv pip install *.tar.gz

  unit_tests:
    name: Run Unit Tests
    needs: [changes, matrix_prep, code_checking]
    strategy:
      matrix: ${{fromJson(needs.matrix_prep.outputs.matrix)}}
    runs-on: ${{ matrix.runs_on }}
    if: github.ref_type == 'branch'
    steps:
      - name: Checkout
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        uses: actions/checkout@v4
      - name: Set up Python
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        uses: actions/setup-python@v5.1.0
        with:
          python-version: ${{ matrix.python-version }}
      # We have to install UV because (for now) these run in GH's runners
      - name: Setup uv
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true
          cache-dependency-glob: "**/requirements*.txt" 
      - name: Install dependencies
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        run: |
          uv pip install .
          uv pip install -r requirements/requirements-test.txt
          uv pip install .[lightwood]  # TODO: for now some tests rely on lightwood
          uv pip install .[mssql]
          uv pip install .[clickhouse]
          uv pip install .[snowflake]
          uv pip install .[web]
          uv pip install .[redshift]
          uv pip install .[bigquery]
          uv pip install .[elasticsearch]
          uv pip install .[databricks]
          uv pip install .[oracle]
          uv pip install .[db2]
          uv pip install .[hive]
          uv pip install .[teradata]
          uv pip install .[hana]
          uv pip install .[minds_endpoint]
          uv pip freeze
      - name: Run unit tests
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        run: |
          if [ "$RUNNER_OS" == "Linux" ]; then
            env PYTHONPATH=./ pytest tests/unit/executor/ -x
            env PYTHONPATH=./ pytest tests/unit/test_llm_utils.py
            env PYTHONPATH=./ pytest tests/unit/ml_handlers/test_minds_endpoint.py
            env PYTHONPATH=./ pytest tests/unit/ml_handlers/test_openai.py
            # env PYTHONPATH=./ pytest tests/unit/ml_handlers/test_anyscale_endpoints.py
          fi
      - name: Run Handlers tests and submit Coverage to coveralls
        if: ${{ needs.changes.outputs.not-docs == 'true' }}
        run: |
          handlers=("mysql" "postgres" "mssql" "clickhouse" "snowflake" "web" "redshift" "bigquery" "elasticsearch" "s3" "databricks" "dynamodb" "mariadb" "oracle" "mongodb" "db2" "hive" "teradata" "hana")
          for handler in "${handlers[@]}"
          do
            pytest --cov=mindsdb/integrations/handlers/${handler}_handler tests/unit/handlers/test_${handler}.py 
          done

          # Dont run coveralls for PRs from forks
          if [ ${{ github.event.pull_request.head.repo.full_name }} == ${{ github.repository }} ]; then
            coveralls --service=github --basedir=mindsdb/integrations/handlers
          fi
        env:
          COVERALLS_REPO_TOKEN: ${{ secrets.COVERALLS_REPO_TOKEN }}
          github_token: ${{ secrets.REPO_DISPATCH_PAT_TOKEN }}
