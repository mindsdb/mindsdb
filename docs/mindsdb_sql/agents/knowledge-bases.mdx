---
title: Knowledge Base
sidebarTitle: Knowledge Base
---

A knowledge base is an advanced system designed to go beyond traditional data storage. Its components include embedding and reranking models and a vector store.

<p align="center">
  <img src="https://docs.google.com/drawings/d/e/2PACX-1vTVmUqhoFXLF3ncL0NWwgdPjI7Hj19f-5xU8ED31ntYvlsTM3poM9zZKwcrEwzvxJrOhl2raIFKWlsp/pub?w=1342&h=681" />
</p>

It intelligently organizes information in semantically meaningful ways, allowing for context-aware retrieval based on meaning rather than just keywords. With the ability to perform semantic reasoning across multiple pieces of information, it delivers deeper insights and more accurate responses.

## Create a Knowledge Base

Here is the syntax for creating a knowledge base:

<Note>
MindsDB stores objects, such as models or knowledge bases, inside projects. The default project is called `mindsdb`. You can [create other projects](/mindsdb_sql/sql/create/project) to store your objects.

To refer to an object stored in a defined project, specify both project and object names separated by a dot: `project_name.object_name`. For example, `my_project.my_kb`. If no project is defined with the object name, the object is stored in the default `mindsdb` project.
</Note>

<CodeGroup>

```sql OpenAI
CREATE KNOWLEDGE_BASE my_kb
USING
     embedding_model = {
         "provider": "OpenAI",
         "model_name" : "text-embedding-ada-002",
         "api_key": "sk-..."  -- optional, default from env variable
     },
     reranking_model = {
         "provider": "OpenAI",
         "model_name": 'gpt-4o',
         "api_key": "sk-..."  -- optional, default from env variable
     },
     storage = my_vector_store.storage_table, -- optional, default ChromaDB
     metadata_columns = ['date', 'creator', ...], -- optional
     content_columns = ['review', 'content', ...], -- optional, default content
     id_column = 'id'; -- optional
```

```sql OpenAI via Azure
CREATE KNOWLEDGE_BASE my_kb
USING
     embedding_model = {
         "provider": "Azure_OpenAI",
         "model_name" : "text-embedding-ada-002",
         "api_key": "sk-...",  -- optional, default from env variable
         "azure_endpoint" : "https://ai-2249ai742481026689.openai.azure.com/",
         "openai_api_version": "2024-12-01-preview"
     },
     reranking_model = {
         "provider": "OpenAI",
         "model_name": 'gpt-4o',
         "api_key": "sk-..."  -- optional, default from env variable
     },
     storage = my_vector_store.storage_table, -- optional, default ChromaDB
     metadata_columns = ['date', 'creator', ...], -- optional
     content_columns = ['review', 'content', ...], -- optional, default content
     id_column = 'id'; -- optional
```

</CodeGroup>

Upon execution, it registers `my_kb` and associates the specified models and storage.

The following is an explanation of the syntax and parameters:

* `embedding_model` stores specifications of the embedding model to be used.
      * `provider` defines the model provider. Currently, the supported providers include OpenAI and its models via Azure.
      * `model_name` defines the embedding model name as specified by the provider. Users can choose one of the [OpenAI embedding models](https://platform.openai.com/docs/guides/embeddings/embedding-models#embedding-models).
      * `api_key` stores your OpenAI API key. Alternatively, you can use the `OPENAI_API_KEY` environment variable to store your OpenAI API key.
      * `azure_endpoint` is required when using `Azure_OpenAI` as the provider.
      * `openai_api_version` is required when using `Azure_OpenAI` as the provider.

* `reranking_model` stores specification of the reranking model to be used.
      * `provider` defines the model provider. Currently, the supported providers include OpenAI.
      * `model_name` defines the reranking model name as specified by the provider. Users can choose one of the [OpenAI chat models](https://platform.openai.com/docs/models).
      * `api_key` stores your OpenAI API key. Alternatively, you can use the `OPENAI_API_KEY` environment variable to store your OpenAI API key.

* `storage` is an optional parameter. It assigns the name of the vector store created within MindsDB with the [`CREATE DATABASE` command](/mindsdb_sql/sql/create/database), which is either [PGVector](/integrations/vector-db-integrations/pgvector) or [ChromaDB](/integrations/vector-db-integrations/chromadb), followed by a table name present in that vector database where the knowledge base stores its content. If not provided, the system uses the default ChromaDB vector database.

* `metadata_columns` provides the list of column names that will be used as the `metadata` of the knowledge base. Users can use these column names to filter the results by metadata and insert them into the knowledge base. If not set, the metadata is not used.

* `content_columns` provides the list of column names that will be used as the `content` of the knowledge base. Users can use these column names to filter the results by content and insert them into the knowledge base. If not set, the `content` column is used by default.

* `id_column` is the column name that will be used as the unique identifier by the knowledge base. If not set, the `id` column is used by default.

Get details about the knowledge base using the `DESCRIBE` command.

```sql
DESCRIBE KNOWLEDGE_BASE my_kb;
```

<Accordion title="Examples">

Here are the usage examples:

* Creating a knowledge base:

```sql
CREATE KNOWLEDGE_BASE my_kb
USING
     embedding_model = {
         "provider": "OpenAI",
         "model_name" : "text-embedding-ada-002",
         "api_key": "sk-..."  -- optional, default from env variable
     },
     reranking_model = {
         "provider": "OpenAI",
         "model_name": 'gpt-4o',
         "api_key": "sk-..."  -- optional, default from env variable
     },
     metadata_columns = ['country'],
     content_columns = ['country', 'population', 'areasquarekm', 'populationdensity'],
     id_column = 'country_id';
```
</Accordion>

## Insert into a Knowledge Base

Here is the syntax for inserting into a knowledge base:

```sql
INSERT INTO my_kb ( 
      SELECT <id_col> AS id, <text_col> AS content 
      FROM <source_table> 
);
```

Upon execution, it inserts data into a knowledge base, using the embedding model to embed it into vectors before inserting into an underlying vector database.

The following is an explanation of the syntax and parameters:

* `my_kb` is a unique identifier of a knowledge base.
* `<id_col>` is a column that contains unique identifiers of data. Note that if you specified the `id_column` parameter when creating the knowledge base, you can insert this column name into the knowledge base without the `AS id` alias.
* `<text_col>` is a column that contains the text content. Note that if you specified the `content_columns` parameter when creating the knowledge base, you can insert these column names into the knowledge base without the `AS content` alias.

<Accordion title="Partitioning Queries for Better Performance">

The following features are covered here:

- Run the `INSERT INTO` query in partitions where a batch can be split into separate workers for improved performance.
- Track progress of the query and resume or cancel ongoing queries.
- When a query is finished, it is stored in the `information_schema.queries` table with the `finished_at` timestamp. If a user runs another query, all finished queries older than one day are removed.
- Option to skip errors in partitions.

**Examples of statements**

```sql
-- Insert data from table into a knowledge base
INSERT INTO my_kb 
SELECT * 
FROM db1.table1
WHERE ws_id = 3
USING 
      batch_size=200,
      track_column=id;

-- Insert predictions (made by joining a table with a model) into a knowledge base
INSERT INTO my_kb
SELECT * 
FROM db1.table1
JOIN my_model
USING 
      batch_size=200, 
      track_column=id, 
      threads=true;

-- Insert data from table into a knowledge base while skipping errors
INSERT INTO my_kb
SELECT * 
FROM db1.table1
USING 
      batch_size=200, 
      track_column=id, 
      threads=10, 
      error='skip';

-- Perform prediction in threads and return data 
INSERT INTO my_kb
SELECT * 
FROM db1.table1
JOIN my_model
USING 
      batch_size=200, 
      track_column=id, 
      threads=10;

-- View queries in progress
SELECT * FROM information_schema.queries;
```

**Parameters**

- **batch_size** - Number of rows fetched per iteration/batch (default: `1000`) to optimize data extraction from the source.
- **threads** - Defines threads to run partitions in. Note that if the [ML task queue](/setup/custom-config#overview-of-config-parameters) is enabled, threads are automatically used for prediction. Allowed values for `threads` include:
  - `int` - Number of threads.
  - `true` - Auto-detect thread count.
  - `false` - Disable threads, even if the ML task queue is enabled.
- **track_column** - Column used for partitioning. The query is sorted by this column and limited by `batch_size`.
- **error** - Defines the error processing. Its default value is `raise`. To skip errors in partitions, use `error='skip'`.

**Repeat a query**

If a query fails, its state is saved as follows:
- Current step number (in database)
- Current step data (cached in files or Redis)

Users can resolve the issue and resume the query:

```sql
-- Use the query ID
SELECT query_resume(1);
```

Or, remove/cancel a query:

```sql
-- Use the query ID
SELECT query_cancel(1);
```
</Accordion>

<Accordion title="Examples">

Here are the usage examples:

* Inserting into a knowledge base where the `content_columns` and `id_column` parameters were not specified:

```sql
INSERT INTO my_kb ( SELECT book_id AS id, book_summary AS content FROM my_books );
```

* Inserting into a knowledge base where the `content_columns` and `id_column` parameters were specified as follows:

```sql
content_columns = ["book_title", "book_summary"]
id_column = "book_id"
```

```sql
INSERT INTO my_kb ( SELECT book_id, book_title, book_summary FROM my_books );
```
</Accordion>

## Search a Knowledge Base

### Semantic Search at the Document Level

KBs provide semantic search returning document-level relevance.

```sql
SELECT id, relevance 
FROM <kb_name> 
WHERE content = '<query_text>' 
AND reranking_threshold = 0.6 -- optional
LIMIT <N>;
```

Upon execution, it performs the semantic search workflow (including embedding the query, searching vectors, and optionally reranking) and returns document identifiers and relevance scores.

The following is an explanation of the syntax and parameters:

* `SELECT id, relevance` specifies that the unique document identifier and its calculated relevance score should be returned.
* `<kb_name>` is a unique identifier of a knowledge base.
* `WHERE content = '<query_text>'` triggers semantic search based on the meaning of `<query_text>`.
* `AND reranking_threshold = 0.6` is an optional filtering condition. It limits the output based on the relevance score and can have values between 0 and 1.
* `LIMIT <N>` restricts results to the top N most relevant documents.

<Note>
Here are the conditions supported by the available vector stores:

| Handler  |  IN, NOT IN | LIKE, NOT LIKE | < and > | !=  |
| -------- | ----------- | -------------- | ------- | --- |
| PgVector | +           | +              | +       | +   |
| ChromaDB | +           | -              | -       | +   |
</Note>

<Accordion title="Examples">

Here are the usage examples:

* Returning top k most relevant documents:

```sql
SELECT id, relevance 
FROM my_kb 
WHERE content = 'a novel about epic inter planetary intelligence' 
AND reranking_threshold = 0.7
LIMIT 10;
```
</Accordion>

### Semantic Search at the Chunk Level

KBs provide semantic search returning chunk-level details.

```sql
SELECT id, chunk_id, chunk_content, metadata, distance, relevance
FROM <kb_name> 
WHERE content = '<query_text>' 
AND reranking_threshold = 0.6 -- optional
LIMIT <N>;
```

Upon execution, it performs the semantic search workflow (including embedding the query, searching vectors, and optionally reranking) and returns details pertaining to the specific text chunks that matched the query most closely.

The following is an explanation of the syntax and parameters:

* `SELECT id, chunk_id, chunk_content, metadata, distance, relevance` specifies that the unique document identifier, chunk identifier, chunk content, metadata (if defined), distance, and relevance should be returned.
* `<kb_name>` is a unique identifier of a knowledge base.
* `WHERE content = '<query_text>'` triggers semantic search based on the meaning of `<query_text>`.
* `AND reranking_threshold = 0.6` is an optional filtering condition. It limits the output based on the relevance score and can have values between 0 and 1.
* `LIMIT <N>` restricts results to the top N most relevant documents.

<Accordion title="Examples">

Here are the usage examples:

* Returning top k most relevant chunks:

```sql
SELECT id, chunk_id, chunk_content, relevance 
FROM my_kb 
WHERE content = 'a novel about epic inter planetary intelligence' 
AND reranking_threshold = 0.7
LIMIT 10;
```
</Accordion>

### Metadata Filtering with Semantic Search

KBs combine semantic search with standard SQL filtering on metadata.

```sql
SELECT id, chunk_content, relevance 
FROM my_kb 
WHERE id LIKE '<id_pattern>' -- metadata filtering conditions
AND content = '<query_text>' -- semantic search condition
AND reranking_threshold = 0.6; -- optional
```

Upon execution, it performs the conjunctive filtering, that is, results must satisfy both the metadata condition(s) and the semantic search condition.

The following is an explanation of the syntax and parameters:

* `SELECT id, chunk_content, relevance` specifies that the unique document identifier, chunk content, and the relevance score should be returned.
* `<kb_name>` is a unique identifier of a knowledge base.
* `WHERE id LIKE '<id_pattern>'` is the metadata filtering condition.
* `WHERE content = '<query_text>'` is the semantic search condition.
* `AND reranking_threshold = 0.6` is an optional filtering condition. It limits the output based on the relevance score and can have values between 0 and 1.

<Accordion title="Examples">

Here are the usage examples:

* Filtering results:

```sql
SELECT id, chunk_content, relevance 
FROM my_kb
WHERE id LIKE 'fiction%' -- metadata filtering conditions
AND content = 'a novel about ...' -- semantic search condition
AND reranking_threshold = 0.6; -- optional
```
</Accordion>

## `JOIN` Support

KBs can be used in the standard SQL JOIN statements.

```sql
SELECT t.id, t.title, kb.chunk_content, kb.relevance
FROM <other_table> AS t
JOIN <kb_name> AS kb 
ON t.<key_col> = kb.id
WHERE <table_filter_condition> -- filter on non-KB table
AND kb.content = '<query_text>'; -- semantic search filter on a KB
```

The following is an explanation of the syntax and parameters:

* `SELECT t.id, t.title, kb.chunk_content, kb.relevance` specifies the columns selected from a table (`t`) and a knowledge base (`kb`).
* `WHERE <table_filter_condition>` sets conditions on a table.
* `AND kb.content = '<query_text>'` sets a semantic search condition on a knowledge base.

<Accordion title="Examples">

Here are the usage examples:

* Joining a knowledge base with a data table:

```sql
SELECT b.id, b.title, kb.chunk_content, kb.relevance
FROM books AS b
LEFT JOIN my_kb AS kb 
ON b.id = kb.id
WHERE b.topic = 'fantasy'
AND kb.content = 'a novel about benevolent ai';
```
</Accordion>

## Delete from a Knowledge Base

Here is the syntax for deleting from a knowledge base:

```sql
DELETE FROM <kb_name> 
WHERE <condition>;
```

Upon execution, it identifies matching records based on the user-defined condition and removes all associated data (metadata, content, chunks, embeddings) for matching records from the KB's storage.

The following is an explanation of the syntax and parameters:

* `<kb_name>` is a unique identifier of a knowledge base.
* `<condition>` is a standard SQL WHERE clause condition operating on metadata columns.

<Accordion title="Examples">

Here are the usage examples:

* Deleting from a knowledge base:

```sql
DELETE FROM my_kb 
WHERE id IN ('scifi_001', 'scifi_0010', 'bus_89');
```
</Accordion>

## Drop a Knowledge Base

Here is the syntax for deleting a knowledge base:

```sql
DROP KNOWLEDGE_BASE <kb_name>;
```

Upon execution, it removes the knowledge base with its content.

<Accordion title="Examples">

Here are the usage examples:

* Dropping a knowledge base:

```sql
DROP KNOWLEDGE_BASE my_kb;
```
</Accordion>
