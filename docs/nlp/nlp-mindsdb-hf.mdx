---
title: NLP with MindsDB and Hugging Face
---

## MindsDB NLP Supported Tasks

There are four main NLP tasks currently supported by MindsDB:

- Text Classification
- Zero-Shot Classification
- Translation
- Summarization

<Tip>
Currently, MindsDB's NLP engine is powered by [Hugging Face](https://huggingface.co/). But we plan to expand to other NLP options in the future, so stay tuned!
</Tip>

<Tip>
The MindsDB's Hugging Face engine is extensible. We are actively working on adding more tasks and models.
If you have a specific task or model in mind, please let us know in the [MindsDB Community](https://community.mindsdb.com/).
</Tip>

## MindsDB NLP Tested Models

<AccordionGroup>
    <Accordion title="Text Classification" defaultOpen="true">
        Completes the task of assigning a label to a text. For example, you can use it to classify a movie review as positive or negative.
        ##### Supported Models
        - [Spam detection](https://huggingface.co/mariagrandury/roberta-base-finetuned-sms-spam-detection)
        - [Sentiment analysis](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment)
        - [Sentiment analysis Spanish](https://huggingface.co/pysentimiento/robertuito-sentiment-analysis)
        - [Sentiment analysis finance](https://huggingface.co/ProsusAI/finbert)
        - [Emotions classifier](https://huggingface.co/j-hartmann/emotion-english-distilroberta-base)
        - [Emotions classifier Ekmanm's 6 emotions](https://huggingface.co/j-hartmann/emotion-english-distilroberta-base)
        - [Toxicity classifier](https://huggingface.co/SkolkovoInstitute/roberta_toxicity_classifier)
        - [Environmental, Social, and Governance (ESG) 4 classifier](https://huggingface.co/yiyanghkust/finbert-esg)
        - [Environmental, Social, and Governance (ESG) 26 classifier](https://huggingface.co/nbroad/ESG-BERT)
        - [Hate speech classifier](https://huggingface.co/Hate-speech-CNERG/bert-base-uncased-hatexplain)
        - [Crypto Signals classifier](https://huggingface.co/ElKulako/cryptobert)
        - [US political party classifier](https://huggingface.co/m-newhauser/distilbert-political-tweets)
        - [Question Detection](https://huggingface.co/shahrukhx01/bert-mini-finetune-question-detection)
        - [Industry classifier](https://huggingface.co/sampathkethineedi/industry-classification)

    </Accordion>
    <Accordion title="Zero-Shot Classification" defaultOpen="true">
        Completes the task of assigning a label to a text without training on the labels.
        For example, you can use it to classify a movie review as positive or negative without training on positive or negative labels.
        ##### Supported Models
        -[BART](https://huggingface.co/facebook/bart-large-mnli)
    </Accordion>

    <Accordion title="Translation" defaultOpen="true">
        Completes the task of translating a text from one language to another. For example, you can use it to translate a text from English to French.
        ##### Supported Models
        - [English to French T5](https://huggingface.co/t5-base)
        - [French to English T5](https://huggingface.co/t5-base)
        - [Spanish to English](https://huggingface.co/Helsinki-NLP/opus-mt-es-en)
    </Accordion>

    <Accordion title="Summarization" defaultOpen="true">
        Completes the task of summarizing a text. For example, you can use it to summarize an abstract into a title.
        ##### Supported Models
        - [BART](https://huggingface.co/sshleifer/distilbart-cnn-12-6)
        - [Google Pegasus](https://huggingface.co/google/pegasus-xsum)
    </Accordion>

</AccordionGroup>

The Hugging Face models are used to perform these tasks.
Keep in mind that usually there is more than one model for each task,
so you can choose the one that suits you best.

## How to Bring the Hugging Face Model to MindsDB

We use the [`CREATE MODEL`](/sql/create/predictor) statement to bring the Hugging Face models to MindsDB.

Generally, it looks like this:

```sql
CREATE MODEL project_name.predictor_name        -- AI TABLE TO STORE THE MODEL
PREDICT target_column                           -- NAME OF THE COLUMN TO STORE PREDICTED VALUES
USING
  engine = 'huggingface',                       -- USING THE HUGGING FACE ENGINE
  task = 'task',                                -- TASK OF CLASSIFYING TEXT (OPTIONAL)
  model_name = 'model_name_from_hugging_face',  -- MODEL NAME UNDER THE HUGGING FACE MODEL HUB
  input_column = 'input_column',                -- COLUMN NAME OF THE INPUT DATA
  labels = ['label', 'label_1'];                -- ARRAY OF LABELS
```

Where:

| Expressions      | Description                                                                                         |
| ---------------- | --------------------------------------------------------------------------------------------------- |
| `project_name`   | Name of the project where the model is created. By default, the `mindsdb` project is used.          |
| `predictor_name` | Name of the model to be created.                                                                    |
| `target_column`  | Column to store the predicted values.                                                               |
| `engine`         | Optional. You can provide an ML engine, based on which the model is created.                        |
| `task`           | Optional. It is relative to the Hugging Face task tag.                                              |
| `model_name`     | Model name from the Hugging Face model hub.                                                         |
| `input_column`   | Name of the column that has the input data, especially important for batch predictions using JOIN.  |
| `labels`         | Depending on the model. Usually used for Zero-Shot Classification models.                           |

### Example

Let's go through a Spam Classification example to understand better how
to link Hugging Face models and bring them to MindsDB as AI tables.

<Note>
    **Using Local Installation of MindsDB**

    Please note that if you use a local installation of MindsDB, instead of MindsDB Cloud, you should install `transformers==4.21.0` to be able to use the Hugging Face models.

</Note>

```sql
CREATE MODEL mindsdb.spam_classifier                           
PREDICT PRED                           
USING
  engine = 'huggingface',              
  task = 'text-classification',        
  model_name = 'mrm8488/bert-tiny-finetuned-sms-spam-detection', 
  input_column = 'text_spammy',        
  labels = ['ham', 'spam'];
```

Where:

| Expressions      | Values                                                                                                                  |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------- |
| `project_name`   | mindsdb                                                                                                                 |
| `predictor_name` | spam_classifier                                                                                                         |
| `target_column`  | PRED                                                                                                                    |
| `engine`         | huggingface                                                                                                             |
| `task`           | text-classification                                                                                                     |
| `model_name`     | [mrm8488/bert-tiny-finetuned-sms-spam-detection](https://huggingface.co/mrm8488/bert-tiny-finetuned-sms-spam-detection) |
| `input_column`   | text_spammy                                                                                                             |
| `labels`         | ['ham', 'spam']                                                                                                         |


On execution, we get:

```sql
Query successfully completed
```

Before querying for predictions, we should verify the status of the `spam_classifier` model.

```sql
SELECT *
FROM mindsdb.models
WHERE name = 'spam_classifier';
```

On execution, we get:

```sql
+---------------+-------+--------+--------+-------+-------------+---------------+------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|NAME           |PROJECT|STATUS  |ACCURACY|PREDICT|UPDATE_STATUS|MINDSDB_VERSION|ERROR |SELECT_DATA_QUERY|TRAINING_OPTIONS                                                                                                                                                                                               |
+---------------+-------+--------+--------+-------+-------------+---------------+------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|spam_classifier|mindsdb|complete|[NULL]  |PRED   |up_to_date   |22.10.2.1      |[NULL]|[NULL]           |{'target': 'PRED', 'using': {'engine': 'huggingface', 'task': 'text-classification', 'model_name': 'mrm8488/bert-tiny-finetuned-sms-spam-detection', 'input_column': 'text_spammy', 'labels': ['ham', 'spam']}}|
+---------------+-------+--------+--------+-------+-------------+---------------+------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

Once the status is `complete`, we can query for predictions.

```sql
SELECT h.PRED, h.PRED_explain, t.text_spammy AS input_text
FROM example_db.demo_data.hf_test AS t
JOIN mindsdb.spam_classifier AS h;
```

On execution, we get:

```sql
+----+---------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+
|PRED|PRED_explain                                             |input_text                                                                                                                                                       |
+----+---------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+
|spam|{'spam': 0.9051626920700073, 'ham': 0.09483727067708969} |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's      |
|ham |{'ham': 0.9380123615264893, 'spam': 0.061987683176994324}|Nah I don't think he goes to usf, he lives around here though                                                                                                    |
|spam|{'spam': 0.9064534902572632, 'ham': 0.09354648739099503} |WINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.    |
+----+---------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

For the full library of supported examples please go [here](/nlp/nlp-extended-examples).
