# MindsDB Data Source Integration (DSI) Testing Framework

This project contains a powerful, configuration-driven, automated testing framework for MindsDB data source integrations using pytest.

## Core Features

* **Dynamic Test Generation**: Automatically discovers tables (or API endpoints) for any connected data source and generates a standard set of health-check tests.
* **Universal Handler Support**: Uses the MindsDB-native `SHOW TABLES` command to ensure autodiscovery works for both SQL databases and API-based handlers (like GitHub).
* **Configuration-Driven**: Easily add new data sources and their credentials in a single `.env` file without changing any test code.
* **Extensible Custom Tests**: In addition to the autogenerated tests, you can add more complex, custom queries for any data source via simple JSON configuration files.
* **Comprehensive Logging**: Automatically generates a detailed JSON log of every query executed, including failures, for easy debugging.

## Setup

1.  **Create and activate a virtual environment:**
    ```bash
    uv venv
    source .venv/bin/activate  # On Windows, use `.venv\Scripts\activate`
    ```

2.  **Install dependencies:**
    ```bash
    uv pip install -r requirements.txt
    ```

3.  **Configure Environment:**
    * Copy the `.env.example` to a new file named `.env`.
    * Fill in the `.env` file with your MindsDB server details and the credentials for any data sources you wish to test.
    * **Important**: Also fill in the `PG_LOG_*` variables for the PostgreSQL database where test results will be stored.

## Running Tests

To run the full test suite, execute the following command from the root of the `dsi_testing_framework` directory:

```bash
pytest -v -s

```

## How to Add a New Data Source
Adding tests for a new data source is simple and requires no code changes.

1. Add Credentials to .env: Add the necessary environment variables for the new data source to your .env file (e.g., MYSQL_HOST, MYSQL_USER).

2. Update config.py: In dsi_testing_framework/tests/utils/config.py, add a new HANDLERNAME_CREDS dictionary that loads these environment variables.

3. Add to HANDLERS_TO_TEST: Add the name of the new handler to the HANDLERS_TO_TEST list in your .env file.

The framework will now automatically discover and run the standard health-check tests for your new data source.

## Ingesting Test Results
This framework supports storing test execution results in a PostgreSQL database for analytics.

- **Step 1**: Generate the JSON Report
Run pytest with the --json-report flag to generate a detailed JSON file of the test run.

```Bash

# Create the reports directory if it doesn't exist.
mkdir -p reports

# Run pytest and save the report.
pytest --json-report --json-report-file=reports/report.json
```

- **Step 2:** Run the Ingestion Script
After the report is generated, run the ingestion script to parse the file and upload the results to your PostgreSQL database.

```Bash
python scripts/ingest_report.py
```

### Our Priority List for New Data Sources
Here is the prioritized list of the next data sources we plan to integrate into the framework. The checkmarks indicate the data sources that are already tested.

- Postgres: ✅

- GitHub: ✅

-Databricks: ✅

- Parquet in S3 ✅

- Jira ✅ ( there is currently a bug in the jira handler)

- SQL Server ✅

- MariaDB ✅

- MySQL ✅

- Redshift (X) 